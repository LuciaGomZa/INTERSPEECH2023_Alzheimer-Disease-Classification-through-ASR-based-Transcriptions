{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5460c219",
   "metadata": {},
   "source": [
    "# Automatic Speech Recognition (ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675dcf5",
   "metadata": {},
   "source": [
    "## 1) Wav2Vec2: wav2vec2-xls-r-1b-english, wav2vec2-large-xlsr-53-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe4ea21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingsound import SpeechRecognitionModel\n",
    "\n",
    "# Select model\n",
    "model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
    "# model_name = \"jonatasgrosman/wav2vec2-xls-r-1b-english\"\n",
    "\n",
    "# Load ASR model\n",
    "model = SpeechRecognitionModel(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a5edc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transcribe audio files from the training set\n",
    "for group in ['cc','cd']:\n",
    "    print(group)\n",
    "    path = 'data/ADReSS-IS2020/train/Full_wave_enhanced_audio/'+ group + '/'\n",
    "    path_save = 'data/ADReSS-IS2020/train/transcription_ASR_full_'+model_name.split('/')[1]+'/'+ group + '/'\n",
    "    files = os.listdir(path)\n",
    "    tic = time.time()\n",
    "    for file in files:\n",
    "        filename = path + file\n",
    "        transcriptions = model.transcribe([filename])\n",
    "        with open(path_save+file.split('.')[0]+'.json', 'w') as f:\n",
    "            json.dump(transcriptions, f)\n",
    "    toc = time.time()\n",
    "    print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc2a156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transcribe audio files from the test set\n",
    "path = 'data/ADReSS-IS2020/test/Full_wave_enhanced_audio/'\n",
    "path_save = 'data/ADReSS-IS2020/test/transcription_ASR_full_'+model_name.split('/')[1]+'/'\n",
    "\n",
    "files = os.listdir(path)\n",
    "tic = time.time()\n",
    "for file in files:\n",
    "    filename = path + file\n",
    "    transcriptions = model.transcribe([filename])\n",
    "    with open(path_save+file.split('.')[0]+'.json', 'w') as f:\n",
    "        json.dump(transcriptions, f)\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0d00f",
   "metadata": {},
   "source": [
    "## 2.1) Whisper: base, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f76a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# Select model\n",
    "model_name = \"base\"\n",
    "# model_name = \"large\"\n",
    "\n",
    "# Load ASR model\n",
    "model = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5549452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio files from the training set\n",
    "for group in ['cc','cd']:\n",
    "    print(group)\n",
    "    path = 'data/ADReSS-IS2020/train/Full_wave_enhanced_audio/'+ group + '/'\n",
    "    path_save = 'data/ADReSS-IS2020/train/transcription_ASR_full_whisper_large/'+ group + '/' \n",
    "    files = os.listdir(path)\n",
    "    tic = time.time()\n",
    "    for file in files:\n",
    "        filename = path + file\n",
    "        transcriptions = model.transcribe(filename)\n",
    "        with open(path_save+file.split('.')[0]+'.json', 'w') as f:\n",
    "            json.dump(transcriptions, f)\n",
    "    toc = time.time()\n",
    "    print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0f3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio files from the test set\n",
    "path = 'data/ADReSS-IS2020/test/Full_wave_enhanced_audio/'\n",
    "path_save = 'data/ADReSS-IS2020/test/transcription_ASR_full_whisper_large/'\n",
    "\n",
    "files = os.listdir(path)\n",
    "tic = time.time()\n",
    "for file in files:\n",
    "    filename = path + file\n",
    "    transcriptions = model.transcribe(filename)\n",
    "    with open(path_save+file.split('.')[0]+'.json', 'w') as f:\n",
    "        json.dump(transcriptions, f)\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfacb7d",
   "metadata": {},
   "source": [
    "## 2.2) WhisperX: base, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21978c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "\n",
    "# Select model\n",
    "model_name = \"base\"\n",
    "# model_name = \"large\"\n",
    "\n",
    "# Load ASR model\n",
    "model = whisperx.load_model(model_name, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3391daf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transcribe audio files from the training set\n",
    "for group in ['cc','cd']:\n",
    "    print(group)\n",
    "    path = 'data/ADReSS-IS2020/train/Full_wave_enhanced_audio/'+ group + '/'\n",
    "    path_save = 'data/ADReSS-IS2020/train/transcription_ASR_full_whisper_large_X/'+ group + '/' \n",
    "    files = os.listdir(path)\n",
    "    tic = time.time()\n",
    "    for file in files:\n",
    "        filename = path + file\n",
    "        \n",
    "        # Transcribe audio with whisper\n",
    "        result = model.transcribe(filename, language = 'en')\n",
    "        with open(path_save+file.split('.')[0]+'_text.json', 'w') as f:\n",
    "            json.dump(result, f)\n",
    "        \n",
    "        # Load alignment model and metadata and align whisper output\n",
    "        model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "        result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, filename, device)\n",
    "\n",
    "        with open(path_save+file.split('.')[0]+'_alignements.json', 'w') as f:\n",
    "            json.dump(result_aligned['word_segments'], f)\n",
    "        \n",
    "    toc = time.time()\n",
    "    print('Duration:',round((toc-tic)/60,2),'min') # Duration 12.06min + 15.05 min = 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89061083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transcribe audio files from the test set\n",
    "path = 'data/ADReSS-IS2020/test/Full_wave_enhanced_audio/'\n",
    "path_save = 'data/ADReSS-IS2020/test/transcription_ASR_full_whisper_large_X/'\n",
    "\n",
    "files = os.listdir(path)\n",
    "tic = time.time()\n",
    "for file in files:\n",
    "    filename = path + file\n",
    "    \n",
    "    # Transcribe audio with whisper\n",
    "    result = model.transcribe(filename, language = 'en')\n",
    "    with open(path_save+file.split('.')[0]+'_text.json', 'w') as f:\n",
    "        json.dump(result, f)\n",
    "    \n",
    "    # Load alignment model and metadata and align whisper output\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "    result_aligned = whisperx.align(result[\"segments\"], model_a, metadata, filename, device)\n",
    "\n",
    "    with open(path_save+file.split('.')[0]+'_alignements.json', 'w') as f:\n",
    "        json.dump(result_aligned['word_segments'], f)\n",
    "\n",
    "toc = time.time()\n",
    "print('Duration:',round((toc-tic)/60,2),'min')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
